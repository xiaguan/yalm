#include <iostream>
#include <memory>
#include <omp.h>
#include <random>
#include <thread>
#include <vector>

#include "immintrin.h"

#include "model.h"
#include "time.h"

bool floatEquals(float a, float b, float epsilon = 1e-5) {
  return std::abs(a - b) < epsilon;
}

bool arrayEquals(const std::vector<float>& a, const std::vector<float>& b, float epsilon = 1e-4) {
  if (a.size() != b.size()) {
    return false;
  }
  for (size_t i = 0; i < a.size(); i++) {
    if (!floatEquals(a[i], b[i], epsilon)) {
      return false;
    }
  }
  return true;
}

void assertArrayEquals(const std::vector<float>& actual, const std::vector<float>& expected, const std::string& message, float epsilon = 1e-4) {
  if (!arrayEquals(actual, expected, epsilon)) {
    std::cerr << "Assertion failed: " << message << std::endl;
    std::cerr << "actual: ";
    for (size_t i = 0; i < actual.size(); i++) {
      std::cerr << actual[i] << " ";
    }
    std::cerr << std::endl;
    std::cerr << "expected: ";
    for (size_t i = 0; i < expected.size(); i++) {
      std::cerr << expected[i] << " ";
    }
    std::cerr << std::endl;
    exit(1);
  }
}

void assertArrayEquals(float* actual, const std::vector<float>& expected, const std::string& message) {
  std::vector<float> actual_array;
  for (size_t i = 0; i < expected.size(); i++) {
    actual_array.push_back(actual[i]);
  }
  assertArrayEquals(actual_array, expected, message);
}

std::vector<f16_t> float_array_to_half(const std::vector<float>& data) {
#if defined(__AVX2__) && defined(__F16C__)
  std::vector<f16_t> half_data(data.size());
  for (size_t i = 0; i < data.size(); i++) {
    half_data[i] = _cvtss_sh(data[i], 0);
  }
  return half_data;
#else
  assert(false && "Cannot convert to half due to missing F16C extensions");
  return {};
#endif
}

void test_attn() {
  constexpr int TEST_SEQ_LEN = 4;
  constexpr int TEST_DIM = 6;
  constexpr int TEST_HEAD_DIM = 3;
  constexpr int TEST_N_HEADS = 2;
  constexpr int TEST_N_KV_HEADS = 1;
  std::shared_ptr<Config> config = std::make_shared<Config>();
  config->dim = TEST_DIM;
  config->hidden_dim = TEST_DIM;
  config->head_dim = TEST_HEAD_DIM;
  config->n_heads = TEST_N_HEADS;
  config->n_kv_heads = TEST_N_KV_HEADS;
  config->vocab_size = 1;
  config->max_seq_len = TEST_SEQ_LEN;
  InferenceState s(config);
  // (n_heads, head_dim) - query vectors
  std::vector<float> q{
    0., 1e4, 0., // h=0
    0., 0., 1e4 // h=1
  };
  for (size_t i = 0; i < q.size(); i++) {
    s.q()[i] = q[i];
  }
  std::vector<f16_t> kb = float_array_to_half({
    1., 0., 0., // t=0
    0., 1., 0., // t=1
    0., 0., 1., // t=2
    -1., 0., 0. // t=3
  }); // (kv_len, n_kv_heads, head_dim) - buffer containing key vectors of the sequence for all KV heads
  std::vector<f16_t> vb = float_array_to_half({
    1., 0., 0., // t=0
    0., 1., 0., // t=1
    0., 0., 1., // t=2
    -1., 0., 0. // t=3
  }); // (kv_len, n_kv_heads, head_dim) - buffer containing value vectors of the sequence for all KV heads

  // Multihead attention. Iterate over all heads.
  int q_per_kv_head = TEST_N_HEADS / TEST_N_KV_HEADS; // query heads per kv head (for MultiQueryAttention/GroupedQueryAttention)
  int h;
#pragma omp parallel for private(h)
  for (h = 0; h < TEST_N_HEADS; h++) {
    int kv_head_offset = (h / q_per_kv_head) * TEST_HEAD_DIM;
    f16_t* kh = kb.data() + kv_head_offset;
    f16_t* vh = vb.data() + kv_head_offset;
    attn(s.xb(h), s.att(h), s.q(h), kh, vh, TEST_HEAD_DIM, TEST_N_KV_HEADS, TEST_SEQ_LEN);
  }
  // attention scores
  // h=0
  assertArrayEquals(s.att(0), {
    0., 1., 0., 0.
  }, "att(h=0)");
  // h=1
  assertArrayEquals(s.att(1), {
    0., 0., 1., 0.
  }, "att(h=1)");
  assertArrayEquals(s.xb(), {
    0., 1., 0., // h=0
    0., 0., 1. // h=1
  }, "xout");
}

void fill_random(float* data, size_t N, unsigned long seed, float scale_factor = 1.0) {
  std::default_random_engine gen(seed);
  std::normal_distribution<float> dist(0.0, 1.0);
  for (size_t i = 0; i < N; i++) {
    data[i] = dist(gen) * scale_factor;
  }
}

void fill_random(f16_t* data, size_t N, unsigned long seed, float scale_factor = 1.0) {
#if defined(__AVX2__) && defined(__F16C__)
  std::default_random_engine gen(seed);
  std::normal_distribution<float> dist(0.0, 1.0);
  for (size_t i = 0; i < N; i++) {
    data[i] = _cvtss_sh(dist(gen) * scale_factor, 0);
  }
#else
  assert(false && "Cannot fill_random due to missing F16C extensions");
#endif
}

void test_cuda_kernels() {
  int head_dim = 16;
  int n_heads = 16;
  int dim = head_dim * n_heads;
  int hidden_dim = dim;
  int n_kv_heads = 8;
  int max_seq_len = 4;
  int kv_len = 4;

  // matmul
  {
    std::vector<float> w(dim * head_dim);
    fill_random(w.data(), w.size(), 0);
    std::vector<float> x(dim);
    fill_random(x.data(), x.size(), 1);
    std::vector<float> xout_cpu(head_dim);
    std::vector<float> xout_cuda(head_dim);
    matmul_cpu(xout_cpu.data(), x.data(), w.data(), dim, head_dim);
    matmul_cuda(xout_cuda.data(), x.data(), w.data(), dim, head_dim);
    assertArrayEquals(xout_cuda, xout_cpu, "matmul");
  }

  // mha
  {
    std::vector<f16_t> kb(max_seq_len * n_kv_heads * head_dim);
    fill_random(kb.data(), kb.size(), 0);
    std::vector<f16_t> vb(max_seq_len * n_kv_heads * head_dim);
    fill_random(vb.data(), vb.size(), 1);
    std::vector<float> q(n_heads * head_dim);
    fill_random(q.data(), q.size(), 2);
    std::vector<float> att_cpu(n_heads * max_seq_len);
    std::vector<float> att_cuda(n_heads * max_seq_len);
    std::vector<float> xout_cpu(n_heads * head_dim);
    std::vector<float> xout_cuda(n_heads * head_dim);
    mha_cpu(
      xout_cpu.data(),
      att_cpu.data(),
      kb.data(), 
      vb.data(), 
      q.data(), 
      head_dim, kv_len, max_seq_len, n_heads, n_kv_heads
    );
    mha_cuda(
      xout_cuda.data(), 
      att_cuda.data(),
      kb.data(), 
      vb.data(), 
      q.data(), 
      head_dim, kv_len, max_seq_len, n_heads, n_kv_heads
    );
    assertArrayEquals(att_cuda, att_cpu, "mha att");
    assertArrayEquals(xout_cuda, xout_cpu, "mha xout");
  }

  // ffn
  {
    std::vector<float> x(dim);
    fill_random(x.data(), x.size(), 0);
    std::vector<float> w1(dim * hidden_dim);
    fill_random(w1.data(), w1.size(), 1, 1.0 / sqrtf(dim)); 
    std::vector<float> w2(hidden_dim * dim);
    fill_random(w2.data(), w2.size(), 2, 1.0 / sqrtf(hidden_dim));
    std::vector<float> w3(dim * hidden_dim);
    fill_random(w3.data(), w3.size(), 3, 1.0 / sqrtf(dim));
    std::vector<float> xout_cpu(dim);
    std::vector<float> xout_cuda(dim);
    ffn_cpu(
      xout_cpu.data(), 
      x.data(), 
      w1.data(), 
      w2.data(), 
      w3.data(), 
      hidden_dim, dim, 
      ActivationType::GELU
    );
    ffn_cuda(
      xout_cuda.data(), 
      x.data(), 
      w1.data(), 
      w2.data(), 
      w3.data(), 
      hidden_dim, dim, 
      ActivationType::GELU
    );
    assertArrayEquals(xout_cuda, xout_cpu, "ffn");
  }
}

// Helper function to allocate aligned memory
float* allocateAlignedArray(size_t N) {
  // Allocate aligned memory (64-byte alignment for AVX-512)
  void* ptr = nullptr;
  if (posix_memalign(&ptr, 64, N * sizeof(float)) != 0) {
    throw std::bad_alloc();
  }
  return static_cast<float*>(ptr);
}

void mem_bench() {
  constexpr size_t N_THREADS = 32;
  constexpr size_t MB_PER_THREAD = 1024;
  constexpr size_t ELS_PER_THREAD = (MB_PER_THREAD * 1024 * 1024) / sizeof(float);
  constexpr size_t N = N_THREADS * ELS_PER_THREAD;

  std::cout << "Using " << N_THREADS << " threads" << std::endl;
  std::cout << "Allocating " << N_THREADS * MB_PER_THREAD << " MB (" << N << " floats)" << std::endl;
  float* data = allocateAlignedArray(N);

  std::cout << "Filling data..." << std::endl;
#pragma omp parallel for num_threads(N_THREADS)
  for (size_t i = 0; i < N_THREADS; i++) {
    fill_random(data + i * ELS_PER_THREAD, ELS_PER_THREAD, (unsigned long)i);
  }
  std::cout << "Running memory bandwidth test..." << std::endl;

  float totalSum = 0.0;
  uint64_t start = get_timestamp_ms();
#pragma omp parallel for simd reduction(+:totalSum) schedule(guided) aligned(data: 64) num_threads(N_THREADS)
  for (size_t i = 0; i < N; i++) {
    totalSum += data[i];
  }
    
  uint64_t end = get_timestamp_ms();
  float elapsed_s = (end - start) / 1000.0;
  float mb_per_s = N_THREADS * MB_PER_THREAD / elapsed_s;

  std::cout << "Total sum: " << totalSum << std::endl;
  std::cout << "Elapsed time: " << elapsed_s << " s" << std::endl;
  std::cout << "Memory bandwidth: " << mb_per_s << " MB/s" << std::endl;
}

// 64 is the typical cache line size
struct alignas(64) ThreadData {
  volatile uint32_t sink;
  char padding[60]; // Ensures 64-byte alignment/padding
};

void mem_bench2_thread(uint32_t* data, size_t start_idx, size_t elements_per_thread, ThreadData* thread_sink) {
  for (size_t i = start_idx; i < start_idx + elements_per_thread; i++) {
    // 32-bit load stored in volatile to prevent optimization
    thread_sink->sink = data[i];
  }
}

void mem_bench2() {
  constexpr size_t N_THREADS = 64;
  constexpr size_t MB_PER_THREAD = 2048;
  constexpr size_t ELS_PER_THREAD = (MB_PER_THREAD * 1024 * 1024) / sizeof(uint32_t);
  constexpr size_t N = N_THREADS * ELS_PER_THREAD;

  std::cout << "Using " << N_THREADS << " threads" << std::endl;
  std::cout << "Allocating " << N_THREADS * MB_PER_THREAD << " MB (" << N << " uint32_t)" << std::endl;
  uint32_t* data = new uint32_t[N];

  std::cout << "Filling data..." << std::endl;
#pragma omp parallel for num_threads(N_THREADS)
  for (size_t i = 0; i < N_THREADS; i++) {
    for (size_t j = 0; j < ELS_PER_THREAD; j++) {
      data[i * ELS_PER_THREAD + j] = i + j;
    }
  }
  std::cout << "Running memory bandwidth test..." << std::endl;

  // Allocate cache-line aligned sinks for each thread
  std::vector<ThreadData> thread_sinks(N_THREADS);

  uint64_t start = get_timestamp_ms();
  std::vector<std::thread> threads;
  
  // Launch threads
  for (size_t i = 0; i < N_THREADS; i++) {
    threads.emplace_back(mem_bench2_thread, 
      data,
      i * ELS_PER_THREAD, 
      ELS_PER_THREAD,
      &thread_sinks[i]
    );
  }
  
  // Wait for all threads to complete
  for (auto& thread : threads) {
    thread.join();
  }
    
  uint64_t end = get_timestamp_ms();
  float elapsed_s = (end - start) / 1000.0;
  float mb_per_s = N_THREADS * MB_PER_THREAD / elapsed_s;

  std::cout << "Elapsed time: " << elapsed_s << " s" << std::endl;
  std::cout << "Memory bandwidth: " << mb_per_s << " MB/s" << std::endl;
}

void kernel_bench(const std::string& kernel_name) {
  int head_dim = 128;
  int n_heads = 32;
  int dim = head_dim * n_heads;
  int hidden_dim = 14336;
  int n_kv_heads = 8;
  int max_seq_len = 4096;
  int kv_len = 4096;

  if (kernel_name == "matmul") {
    std::vector<f16_t> w(dim * hidden_dim);
    fill_random(w.data(), w.size(), 0);
    std::vector<float> x(dim);
    fill_random(x.data(), x.size(), 1);
    std::vector<float> xout_cuda(hidden_dim);
    matmul_cuda<f16_t>(xout_cuda.data(), x.data(), w.data(), dim, hidden_dim);
  } else if (kernel_name == "matmul-wide") {
    int hidden_dim = 32000;

    std::vector<f16_t> w(dim * hidden_dim);
    fill_random(w.data(), w.size(), 0);
    std::vector<float> x(dim);
    fill_random(x.data(), x.size(), 1);
    std::vector<float> xout_cuda(hidden_dim);
    matmul_cuda<f16_t>(xout_cuda.data(), x.data(), w.data(), dim, hidden_dim);
  } else if (kernel_name == "mha") {
    std::vector<f16_t> kb(max_seq_len * n_kv_heads * head_dim);
    fill_random(kb.data(), kb.size(), 0);
    std::vector<f16_t> vb(max_seq_len * n_kv_heads * head_dim);
    fill_random(vb.data(), vb.size(), 1);
    std::vector<float> q(n_heads * head_dim);
    fill_random(q.data(), q.size(), 2);
    std::vector<float> att_cuda(n_heads * max_seq_len);
    std::vector<float> xout_cuda(n_heads * head_dim);
    mha_cuda(
      xout_cuda.data(), 
      att_cuda.data(),
      kb.data(), 
      vb.data(), 
      q.data(), 
      head_dim, kv_len, max_seq_len, n_heads, n_kv_heads
    );
  } else if (kernel_name == "ffn") {
    std::vector<float> x(dim);
    fill_random(x.data(), x.size(), 0);
    std::vector<f16_t> w1(dim * hidden_dim);
    fill_random(w1.data(), w1.size(), 1, 1.0 / sqrtf(dim)); 
    std::vector<f16_t> w2(hidden_dim * dim);
    fill_random(w2.data(), w2.size(), 2, 1.0 / sqrtf(hidden_dim));
    std::vector<f16_t> w3(dim * hidden_dim);
    fill_random(w3.data(), w3.size(), 3, 1.0 / sqrtf(dim));
    std::vector<float> xout_cuda(dim);
    ffn_cuda<f16_t>(
      xout_cuda.data(), 
      x.data(), 
      w1.data(), 
      w2.data(), 
      w3.data(), 
      hidden_dim, dim, 
      ActivationType::GELU
    );
  } else {
    std::cerr << "Unknown kernel: " << kernel_name << std::endl;
    exit(1);
  }
}

int main(int argc, char* argv[]) {
  if (argc == 2 && std::string(argv[1]) == "-b") {
    std::cout << "Running memory benchmark" << std::endl;
    mem_bench();
  } else if (argc == 2 && std::string(argv[1]) == "-b2") {
    std::cout << "Running memory benchmark 2" << std::endl;
    mem_bench2();
  } else if (argc >= 2 && std::string(argv[1]) == "-bk") {
    if (argc != 3) {
      std::cerr << "Usage: " << argv[0] << " -bk <kernel_name>" << std::endl;
      exit(1);
    }
    std::cout << "Running kernel benchmark" << std::endl;
    for (int i = 0; i < 1; i++) {
      kernel_bench(argv[2]);
    }
  } else {
    test_attn();
    test_cuda_kernels();
  }
  std::cout << "All tests passed" << std::endl;
  return 0;
}